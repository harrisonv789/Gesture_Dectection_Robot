{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to include all the required libraries. These will include all the artificial intelligence libraries that are required for this system to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import sklearn.model_selection as sk\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to read the data set that we will be using to train and test data. This can be found in a particular document and assumes that this python notebook is executed in the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_data = pd.read_csv('../../training/sign_mnist_train.csv')\n",
    "raw_testing_data = pd.read_csv('../../training/sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data includes a single row per training set. This means if we look at the rows, it shows each image as a column of pixel values (greyscale) between 0 and 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to specify the labels of each image based on the ID code. The labels are associated with each letter. This means there are 26 different combinations for different images based on the symbols being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to create the data sets. We need to isolate the raw data with the results from both the training and testing data sets. The validation set needs to be created from the training data which is used to validate each of the set. About 20% of the data should be used for validation. Additionally, with the pixel data, we need to get it between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the binary data for the labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "train_data_result = label_binarizer.fit_transform(raw_training_data['label'])\n",
    "test_data_result = label_binarizer.fit_transform(raw_testing_data['label'])\n",
    "\n",
    "# Remove the labels from the data\n",
    "del raw_training_data['label']\n",
    "del raw_testing_data['label']\n",
    "\n",
    "# Get the image data\n",
    "train_data_image = raw_training_data.values / 255\n",
    "test_data_image = raw_testing_data.values / 255\n",
    "\n",
    "# Reshape the image data\n",
    "train_data_image = train_data_image.reshape(-1,28,28,1)\n",
    "test_data_image = test_data_image.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the lines of data in the CSV handles different letters in the form of a 28x28 pixel image. For example, let's look at the first image of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd4f9e976a0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data_image[0].reshape(28, 28) , cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some operating system settings that must be set up to make the kernel work with the neural network. This can be done using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating the convalutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify the CNN for the number of nodes and layers within the network. Playing around with these numbers will result in differences for accuracy and time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_37 (Conv2D)          (None, 28, 28, 75)        750       \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 28, 28, 75)       300       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 14, 14, 75)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 14, 14, 50)        33800     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 14, 14, 50)        0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 14, 14, 50)       200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 7, 7, 50)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 7, 7, 25)          11275     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 7, 7, 25)         100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 4, 4, 25)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               205312    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 24)                12312     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,049\n",
      "Trainable params: 263,749\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 24 , activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a randomiser, that has random data to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Fit the data\n",
    "datagen.fit(train_data_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for the training! This is done with the specified number of epochs and this may take a while to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 49s 223ms/step - loss: 1.0383 - accuracy: 0.6727 - val_loss: 3.5888 - val_accuracy: 0.0931 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 46s 212ms/step - loss: 0.2042 - accuracy: 0.9334 - val_loss: 1.2341 - val_accuracy: 0.5590 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 45s 208ms/step - loss: 0.0997 - accuracy: 0.9676 - val_loss: 0.0888 - val_accuracy: 0.9851 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 45s 209ms/step - loss: 0.0645 - accuracy: 0.9803 - val_loss: 0.0592 - val_accuracy: 0.9813 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 45s 211ms/step - loss: 0.0469 - accuracy: 0.9857 - val_loss: 0.0388 - val_accuracy: 0.9866 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "history = model.fit(datagen.flow(train_data_image, train_data_result, batch_size = 128), epochs = 5, validation_data = (test_data_image, test_data_result), callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can now test with the testing data to ensure that the model is accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 4s 18ms/step - loss: 0.0388 - accuracy: 0.9866\n",
      "Accuracy of the model is: 0.9866145849227905\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model is: %s\" % model.evaluate(test_data_image, test_data_result)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now attempt to save the model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/sign_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/sign_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../../models/sign_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load the model back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../models/sign_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdir\u001b[39m(model))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('../../models/sign_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
